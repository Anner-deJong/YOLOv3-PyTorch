{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_cfg(cfgfile):\n",
    "    \"\"\" \n",
    "    Parse a config file that states the network architecture.\n",
    "    Official Yolo v3 config can be found online and in ./cfg/yolov3.cfg\n",
    "    \n",
    "    Returns a list of dicts, each dict describing a layer in the network\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "\n",
    "    with open(cfgfile) as f:\n",
    "        # read in all lines, except for empty ones. :-1 is to skip the \\n charachter\n",
    "        lines = [line[:-1] for line in f if (line[:-1] != '')]\n",
    "        # FROM TUTORIAL:\n",
    "        lines = [x for x in lines if x[0] != '#']              # get rid of comments\n",
    "        lines = [x.rstrip().lstrip() for x in lines]           # get rid of fringe whitespaces\n",
    "        \n",
    "        # skip through first non block lines. Uncomment second statement to skip 'net' info\n",
    "        while (lines[0][0] != '['): # or (lines[0][:2] == '[n'):\n",
    "            lines = lines[1:]\n",
    "        \n",
    "        # while the file is not empty, parse a new block\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            block = {}\n",
    "            block['type'] = lines[i][1:-1].rstrip()\n",
    "            i += 1\n",
    "            while (i < len(lines)) and (lines[i][0] != \"[\"):\n",
    "                key, val = lines[i].split('=')\n",
    "                block[key.rstrip()] = val.lstrip()             # rstrip() + lstrip() FROM TUTORIAL\n",
    "                i +=1\n",
    "            blocks.append(block)\n",
    "    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = parse_cfg(\"./cfg/yolov3.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_modules(blocks):\n",
    "    # init\n",
    "    net_info = blocks[0]             # store the network meta info separately\n",
    "    mod_list = nn.ModuleList()       # This list will contain all our layers\n",
    "    in_features = 3                  # Previous layer's # output channels (3 for RGB)\n",
    "    out_features = []                # keep track of each layers # output channels\n",
    "    \n",
    "    for idx, block in enumerate(blocks[1:]):\n",
    "        if block['type'] == 'convolutional':\n",
    "            mod_list.append(create_conv_layer(block, in_features, idx))\n",
    "            out_features.append(int(block['filters']))\n",
    "            in_features = out_features[-1]\n",
    "            \n",
    "        elif block['type'] == 'upsample':\n",
    "            mod_list.append(create_upsample_layer(block, idx))\n",
    "            out_features.append(out_features[-1])\n",
    "        \n",
    "        elif block['type'] == 'route':\n",
    "            mod_list.append(create_route_layer(block, idx))\n",
    "            out_feature = sum([out_features[int(i)] for i in block['layers'].split(',')])\n",
    "            out_features.append(out_feature)\n",
    "            in_features = out_features[-1]\n",
    "        \n",
    "        elif block['type'] == 'shortcut':\n",
    "            mod_list.append(create_shortcut_layer(block, idx))\n",
    "            out_features.append(out_features[-1])\n",
    "        \n",
    "        elif block['type'] == 'yolo':\n",
    "            mod_list.append(create_detection_layer(block, idx))\n",
    "            out_features.append(out_features[-1])\n",
    "    \n",
    "        else:\n",
    "            raise ValueError('Block type note recognised/implemented: {}'.format(block['type']))\n",
    "    \n",
    "    return net_info, mod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_info, mod_list = create_modules(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def __init__(self, config_file='./cfg/yolov3.cfg'):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.blocks = parse_cfg(config_file)\n",
    "        self.net_info, self.module_list = create_modules(self.blocks)\n",
    "        \n",
    "    def forward(self, x, gpu_enabled=False):\n",
    "        \n",
    "        modules = self.blocks[1:]  # get rid of 'fake' net-layer\n",
    "        outputs = {}               # store all activation outputs to be accessed by routing and shortcuts\n",
    "        bboxes  = torch.empty(0)   # concatenate all bbox predictions to this initially empty tensor\n",
    "        \n",
    "        # process all modules in order\n",
    "        for i, module in enumerate(modules):\n",
    "            \n",
    "            # convolutional or upsample layer\n",
    "            if module['type'] in ['convolutional', 'upsample']:\n",
    "                x = self.module_list[i](x)\n",
    "                outputs[i] = x\n",
    "            \n",
    "            # shortcut layer\n",
    "            elif module['type'] == 'shortcut':\n",
    "                frm = i + int(module['from'])\n",
    "                x.add_(outputs[frm])\n",
    "                outputs[i] = x\n",
    "            \n",
    "            # route layer\n",
    "            elif module['type'] == 'route':\n",
    "                layers = [int(layer) for layer in module['layers'].split(',')]     # get layers as int in a list\n",
    "                layers = [layer if (layer > 0) else i+layer for layer in layers]   # make all layers absolute\n",
    "                if len(layers) == 1:\n",
    "                    x = outputs[layers[0]]\n",
    "                elif len(layers) == 2:\n",
    "                    x = torch.cat((outputs[layers[0]], outputs[layers[1]]), dim=1) # concatenate layers if more than 1\n",
    "                else:\n",
    "                    ValueError('Routing with more than 2 ({}) layers not implemented'.format(layers))\n",
    "                \n",
    "                outputs[i] = x\n",
    "            \n",
    "            # detection layer\n",
    "            elif module['type'] == 'yolo':\n",
    "                input_size  = int(self.net_info['width'])\n",
    "                anchors     = self.module_list[i][0].anchors\n",
    "                num_classes = int(module['classes'])\n",
    "                \n",
    "                preds       = predict_transform(x, input_size, anchors, num_classes)\n",
    "                bboxes      = torch.cat((bboxes, preds), dim=1)\n",
    "            \n",
    "            else:\n",
    "                raise ValueError('Block type note recognised/implemented: {}'.format(block['type']))\n",
    "                \n",
    "        return bboxes\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet = Darknet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anner/Code/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/Users/anner/Code/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10647, 85])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "out = darknet(torch.randn(1, 3, 32*13, 32*13))\n",
    "print(out.shape)\n",
    "print(out.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([5, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([6, 4])\n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.empty(0)\n",
    "print(a.shape)\n",
    "b = torch.ones(1, 4) * 2\n",
    "print(b.shape)\n",
    "c = torch.ones(5, 4) * 3\n",
    "print(c.shape)\n",
    "\n",
    "ab = torch.cat((a, b), 0)\n",
    "print(ab.shape)\n",
    "ab = torch.cat((ab, c), 0)\n",
    "print(ab.shape)\n",
    "print(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = 0\n",
    "time2 = 0\n",
    "\n",
    "for _ in range(10000):\n",
    "    tic    = time.time()\n",
    "    pred   = predict_transform1(out, anchors=[1, 2, 3], num_classes=80)\n",
    "    time1 += time.time()-tic\n",
    "    \n",
    "    tic    = time.time()\n",
    "    pred   = predict_transform2(out, anchors=[1, 2, 3], num_classes=80)\n",
    "    time2 += time.time()-tic\n",
    "    \n",
    "print('elapsed time for 1: {:.2e}'.format(time1))\n",
    "print('elapsed time for 2: {:.2e}'.format(time2))\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 84 #84, 87\n",
    "print(blocks[n])\n",
    "layers = [int(layer) for layer in blocks[n]['layers'].split(',')]\n",
    "print(len(layers))\n",
    "a = np.arange(9)\n",
    "print(a[layers[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod_list[82][0].anchors)\n",
    "print(mod_list[94][0].anchors)\n",
    "print(mod_list[106][0].anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchorstring = '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326'\n",
    "maskstring = '0,1,2'\n",
    "anchors = [anchor for anchor in anchorstring.split(', ')]\n",
    "print(anchors)\n",
    "mask    = [int(msk) for msk in maskstring.split(',')] #:  0,1,2\n",
    "anchors = [list(map(int, anchors[i].split(','))) for i in mask]\n",
    "print(anchors)\n",
    "# anchors = [[anchors[i], anchors[i+1]] for i in range(0, len(anchors), 2)]\n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = -12\n",
    "\n",
    "print(blocks[n]['type'])\n",
    "conv_block = blocks[n]\n",
    "for key, value in conv_block.items():\n",
    "    print(key, ': ', value)\n",
    "\n",
    "    \n",
    "print([int(i) for i in conv_block['layers'].split(',')])\n",
    "# out_feature = sum([out_features[int(i)] for i in conv_block['layers'].split()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blocks[9])\n",
    "print(len(blocks))\n",
    "for i, item in enumerate(blocks[1:]):\n",
    "    print(i, item['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(9).reshape(3,3)\n",
    "# x = x.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x)\n",
    "print(x.dtype)\n",
    "y = torch.ones(3, 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = nn.Sequential(\n",
    "    nn.Linear(4, 5),\n",
    "    nn.Linear(5, 6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.eye(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.add_(x.type(torch.float))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.matmul(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
